name: Deploy to k3s Cluster

on:
  workflow_run:
    workflows: ["Frontend CI", "Build and Analyze"]
    types: [completed]
    branches: [main, dev]
  push:
    branches: [main, dev]
    paths:
      - 'infra/**'
  workflow_dispatch:

concurrency:
  group: k3s-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  deploy-k3s:
    name: Deploy to k3s
    runs-on: self-hosted
    permissions:
      contents: read
      id-token: write
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' || github.event_name == 'push' }}

    steps:
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ repo checkout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Checkout repository
        uses: actions/checkout@v4

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ logics / tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Display Location Variables
        run: |
          echo "::notice title=Location Check::Using REGION: ${{ secrets.GCP_REGION }}"
          echo "::notice title=Location Check::Using ZONE:   ${{ secrets.GCP_ZONE }}"

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.2
          terraform_wrapper: false

      - name: Set up tools (curl, kubectl, helm)
        run: |
          sudo apt-get update -qq

          command -v curl   >/dev/null || sudo apt-get install -y curl
          command -v kubectl>/dev/null || {
            curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/
          }
          command -v helm   >/dev/null || curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      - name: Install Google Cloud CLI
        timeout-minutes: 10
        run: |
          if ! command -v gcloud &>/dev/null; then
            sudo apt-get remove -y google-cloud-cli google-cloud-sdk || true
            sudo rm -f /etc/apt/sources.list.d/google-cloud-sdk.list /usr/share/keyrings/cloud.google.gpg
            sudo apt-get update -qq
            sudo apt-get install -y apt-transport-https ca-certificates gnupg curl
            echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" \
              | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
            sudo apt-get update -qq && sudo apt-get install -y google-cloud-cli
          fi
          gcloud --version

      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account:            ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}
          project_id:                 ${{ secrets.GCP_PROJECT_ID }}

      - name: Set up Google Cloud CLI with Authentication
        uses: google-github-actions/setup-gcloud@v2
        with:
          install_components: 'gke-gcloud-auth-plugin'

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GCS bucket for backend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Create or Verify GCS State Bucket
        run: |
          BUCKET="${{ secrets.GCS_BUCKET_NAME }}"
          REGION="${{ secrets.GCP_REGION }}"

          if ! gcloud storage buckets describe "gs://$BUCKET" &>/dev/null; then
            gcloud storage buckets create "gs://$BUCKET" \
              --location="$REGION" --uniform-bucket-level-access
            gcloud storage buckets update "gs://$BUCKET" --versioning
            gcloud storage buckets add-iam-policy-binding "gs://$BUCKET" \
              --member="serviceAccount:${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}" \
              --role="roles/storage.objectAdmin"
          fi
          gcloud storage ls "gs://$BUCKET/"

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Terraform vars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Setup terraform.tfvars
        run: |
          cat > infra/terraform/gcp/terraform.tfvars << EOF
          project_id            = "${{ secrets.GCP_PROJECT_ID }}"
          region                = "${{ secrets.GCP_REGION }}"
          zone                  = "${{ secrets.GCP_ZONE }}"
          ssh_user              = "${{ secrets.GCP_SSH_USER }}"
          ssh_public_key_content= "${{ secrets.GCP_SSH_PUBLIC_KEY }}"
          bucket_name           = "${{ secrets.GCS_BUCKET_NAME }}"
          service_account_email = "${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}"
          cloudflare_api_token  = "${{ secrets.CLOUDFLARE_API_TOKEN }}"
          cloudflare_zone_id    = "${{ secrets.CLOUDFLARE_ZONE_ID }}"
          EOF

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Terraform apply â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Deploy Infrastructure
        working-directory: infra/terraform/gcp
        run: |
          cat > backend.conf <<EOF
          bucket = "${{ secrets.GCS_BUCKET_NAME }}"
          prefix = "terraform/state"
          EOF

          terraform init -backend-config=backend.conf
          terraform apply -auto-approve -var-file="terraform.tfvars"

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ download & apply kubeconfig â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Setup k3s cluster
        working-directory: infra/terraform/gcp
        timeout-minutes: 15
        run: |
          rm -f ~/.kube/config
          for i in {1..20}; do
            gcloud storage cp gs://${{ secrets.GCS_BUCKET_NAME }}/k3s-kubeconfig ~/.kube/config && break
            echo "Kubeconfig not yet available, retrying in 20 s ($i/20)"; sleep 20
          done

          if [ ! -f ~/.kube/config ]; then
            echo "::error::Failed to download kubeconfig"; exit 1
          fi

          # ðŸ‘‰use local kubeconfig
          # export KUBECONFIG="$HOME/.kube/config"
          # echo "KUBECONFIG=$KUBECONFIG" >>"$GITHUB_ENV"

          export KUBECONFIG="$HOME/.kube/config"
          CLUSTER=$(kubectl config get-clusters | sed '1d' | head -n1)
          kubectl config set-cluster "$CLUSTER" --insecure-skip-tls-verify=true

          echo "Waiting for API to become readyâ€¦"

          for i in {1..20}; do                      # ~5 min
            kubectl get --raw=/readyz >/dev/null 2>&1 && break
            echo " â†ª  API not ready, retryingâ€¦ ($i/20)"; sleep 15
          done

          echo "Verifying cluster connectivityâ€¦"
          kubectl get nodes

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Create StorageClass â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Create Database StorageClass
        run: |
          kubectl apply -f - <<EOF
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: database-storage
          provisioner: rancher.io/local-path
          reclaimPolicy: Retain
          volumeBindingMode: WaitForFirstConsumer
          allowVolumeExpansion: true
          EOF
          
          echo "âœ… StorageClass created successfully"
          kubectl get storageclass database-storage


      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Upload Database Dumps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Upload Database Dumps to GCS
        run: |
          if [ -d "database" ]; then
            echo "Uploading database dumps..."
            gcloud storage cp database/*.dump gs://${{ secrets.GCS_BUCKET_NAME }}/dumps/
            echo "Done!"
          fi

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helm deploy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Deploy applications with Helm
        env:
          # images from local DHCR
          FRONTEND_IMAGE: "ghcr.io/${{ github.repository }}-frontend:${{ github.event.workflow_run.head_sha || github.sha }}"
          BACKEND_IMAGE:  "ghcr.io/${{ github.repository }}:${{ github.event.workflow_run.head_sha || github.sha }}"
          # â†’ from repo secrets
          DB_NAME:     ${{ secrets.DATABASE_NAME }}
          DB_USER:     ${{ secrets.DATABASE_USERNAME }}
          DB_PASSWORD: ${{ secrets.DATABASE_PASSWORD }}
        run: |
          # â”€â”€â”€ set namespace by branch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            NS="prod"; ENV="prod"
          else
            NS="dev";  ENV="dev"
          fi

          kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -

          # â”€â”€â”€ DATABASE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          helm upgrade --install database ./helm/database \
            --namespace "$NS" \
            --values "environments/$ENV/database-values.yaml" \
            --set persistence.storageClass=database-storage \
            --set postgresql.database="${{ secrets.DATABASE_NAME }}" \
            --set postgresql.username="${{ secrets.DATABASE_USERNAME }}" \
            --set postgresql.password="${{ secrets.DATABASE_PASSWORD }}" \
            --wait --timeout 7m0s --atomic

          # â”€â”€â”€ DATABASE RESTORE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

          echo "[R] Restoring database from dump..."
          echo "[W] Waiting for PostgreSQL to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=database -n "$NS" --timeout=5m

          echo "-> Downloading database dump..."
          gcloud storage cp gs://${{ secrets.GCS_BUCKET_NAME }}/dumps/2024-08-19.dump /tmp/database.dump

          echo "[V] Restoring database..."
          kubectl exec deployment/database -n "$NS" -- sh -c "
            PGPASSWORD=${{ secrets.DATABASE_PASSWORD }} pg_restore \
              -h localhost -U ${{ secrets.DATABASE_USERNAME }} -d ${{ secrets.DATABASE_NAME }} \
              --clean --no-owner --verbose < /dev/stdin
          " < /tmp/database.dump

          rm -f /tmp/database.dump
          echo "âœ… Database restore completed!"
          
          # â”€â”€â”€ BACKEND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          helm upgrade --install backend ./helm/backend \
            --namespace "$NS" \
            --values "environments/$NS/backend-values.yaml" \
            --set image.repository="ghcr.io/${{ github.repository }}" \
            --set image.tag="${{ github.event.workflow_run.head_sha || github.sha }}" \
            --set database.name="${{ secrets.DATABASE_NAME }}" \
            --set database.username="${{ secrets.DATABASE_USERNAME }}" \
            --set database.password="${{ secrets.DATABASE_PASSWORD }}" \
            --wait --timeout 8m --atomic


          # â”€â”€â”€ FRONTEND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          helm upgrade --install frontend ./helm/frontend \
            --namespace "$NS" \
            --values "environments/$ENV/frontend-values.yaml" \
            --set image.repository="ghcr.io/${{ github.repository }}-frontend" \
            --set image.tag="latest" \
            --wait --timeout 5m0s --atomic

          # â”€â”€â”€ overall condition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          kubectl rollout status deploy/database  -n "$NS" --timeout=5m
          kubectl rollout status deploy/backend   -n "$NS" --timeout=5m
          kubectl rollout status deploy/frontend  -n "$NS" --timeout=5m

          kubectl get all -n "$NS"
          kubectl get ingress -n "$NS"

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Argo CD (GitOps) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Setup ArgoCD
        run: |
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd
          echo "ArgoCD admin password: $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d)"

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ trigger GitOps workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Trigger GitOps Workflow
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const ref = process.env.GITHUB_REF || '${{ github.ref }}';
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo:  context.repo.repo,
              workflow_id: 'cd-gitops.yml',
              ref
            });
            console.log(`Triggered cd-gitops.yml for ref: ${ref}`);